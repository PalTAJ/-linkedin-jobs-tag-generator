{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ada0beeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T04:40:56.453121Z",
     "start_time": "2021-10-12T04:40:56.439872Z"
    }
   },
   "outputs": [],
   "source": [
    "import re, nltk, spacy, gensim, os\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import ToktokTokenizer\n",
    "from nltk.stem import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import pandas as pd\n",
    "import emoji\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "f39a0ae1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T05:01:40.406907Z",
     "start_time": "2021-10-12T05:01:40.090787Z"
    }
   },
   "outputs": [],
   "source": [
    "top_tags = []\n",
    "\n",
    "def list_directories(path):\n",
    "    \"\"\"list files and directories in a given path\"\"\"\n",
    "    arr = os.listdir(path)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    ''' Lowering text and removing undesirable marks\n",
    "    '''\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\'\\n\", \" \", text)\n",
    "    text = re.sub(r\"\\'\\xa0\", \" \", text)\n",
    "    text = re.sub('\\s+', ' ', text) # matches all whitespace characters\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "    \n",
    "\n",
    "token = ToktokTokenizer()\n",
    "punct = punctuation\n",
    "    \n",
    "def strip_list_noempty(mylist):\n",
    "    \n",
    "    newlist = (item.strip() if hasattr(item, 'strip') else item for item in mylist)\n",
    "    return [item for item in newlist if item != '']\n",
    "    \n",
    "    \n",
    "def clean_punct(text): \n",
    "    ''' Remove punctuations'''\n",
    "    \n",
    "    words = token.tokenize(text)\n",
    "    punctuation_filtered = []\n",
    "    regex = re.compile('[%s]' % re.escape(punct))\n",
    "    remove_punctuation = str.maketrans(' ', ' ', punct)\n",
    "    \n",
    "    for w in words:\n",
    "        if w in top_tags:\n",
    "            punctuation_filtered.append(w)\n",
    "        else:\n",
    "            w = re.sub('^[0-9]*', \" \", w)\n",
    "            punctuation_filtered.append(regex.sub('', w))\n",
    "  \n",
    "    filtered_list = strip_list_noempty(punctuation_filtered)\n",
    "        \n",
    "    return ' '.join(map(str, filtered_list))\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def stopWordsRemove(text):\n",
    "    ''' Removing all the english stop words from a corpus\n",
    "    Parameter:\n",
    "    text: corpus to remove stop words from it\n",
    "    '''\n",
    "\n",
    "    words = token.tokenize(text)\n",
    "    filtered = [w for w in words if not w in stop_words]\n",
    "    \n",
    "    return ' '.join(map(str, filtered))\n",
    "    \n",
    "    \n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "def lemmatization(texts, allowed_postags, stop_words=stop_words):\n",
    "    ''' It keeps the lemma of the words (lemma is the uninflected form of a word),\n",
    "    and deletes the underired POS tags\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    texts (list): text to lemmatize\n",
    "    allowed_postags (list): list of allowed postags, like NOUN, ADL, VERB, ADV\n",
    "    '''\n",
    "    lemma = wordnet.WordNetLemmatizer()       \n",
    "    doc = nlp(texts) \n",
    "    texts_out = []\n",
    "    \n",
    "    for token in doc:\n",
    "        \n",
    "        if str(token) in top_tags:\n",
    "            texts_out.append(str(token))\n",
    "            \n",
    "        elif token.pos_ in allowed_postags:\n",
    "            \n",
    "            if token.lemma_ not in ['-PRON-']:\n",
    "                texts_out.append(token.lemma_)\n",
    "                \n",
    "            else:\n",
    "                texts_out.append('')\n",
    "     \n",
    "    texts_out = ' '.join(texts_out)\n",
    "\n",
    "    return texts_out\n",
    "    \n",
    "    \n",
    "def strip_emoji(text):\n",
    "#     print(emoji.emoji_count(text))\n",
    "    new_text = re.sub(emoji.get_emoji_regexp(), r\"\", text)\n",
    "    return new_text\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_text(df,column='description'):\n",
    "    \n",
    "    df[column] = df[column].apply(lambda x: clean_text(x))\n",
    "    df[column] = df[column].apply(lambda x:  BeautifulSoup(x).get_text())\n",
    "    df[column] = df[column].apply(lambda x: strip_emoji(x))\n",
    "\n",
    "    df[column] = df[column].apply(lambda x: clean_punct(x)) \n",
    "    df[column] = df[column].apply(lambda x: stopWordsRemove(x)) \n",
    "    df[column] = df[column].apply(lambda x: lemmatization(x, ['NOUN', 'ADV']))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "24909156",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T05:03:00.358418Z",
     "start_time": "2021-10-12T05:03:00.351411Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_tags(df,column='description'):\n",
    "    \n",
    "    countVec =CountVectorizer()\n",
    "    cv = countVec.fit_transform(df[column].str.lower())\n",
    "    cv_feature_names = countVec.get_feature_names()\n",
    "    feature_count = cv.toarray().sum(axis = 0)\n",
    "    feature_count = sorted(dict(zip(cv_feature_names, feature_count)).items(), key=lambda item: item[1])[::-1][:25]\n",
    "\n",
    "    return feature_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "434ed6a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T05:03:00.624993Z",
     "start_time": "2021-10-12T05:03:00.617433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Accounting_25_records.csv',\n",
       " 'Mathematics_173_records.csv',\n",
       " 'Psychologist_75_records.csv',\n",
       " 'Mechanical_Engineering_175_records.csv',\n",
       " 'Pre-Law_&_Legal_Studies_169_records.csv']"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = list_directories('data')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f15035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "f61f2715",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T05:03:01.146336Z",
     "start_time": "2021-10-12T05:03:01.133908Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Accounting',\n",
       " 'Mathematics',\n",
       " 'Psychologist',\n",
       " 'MechanicalEngineering',\n",
       " 'Pre-Law&LegalStudies']"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = []\n",
    "for i in files:\n",
    "    t = ''.join(i.split('_')[:-2])\n",
    "    category.append(t)\n",
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "725f3bc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T05:03:15.857693Z",
     "start_time": "2021-10-12T05:03:01.364313Z"
    }
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for cat, file in zip(category,files):\n",
    "    df = pd.read_csv(f\"data/{file}\") \n",
    "\n",
    "    df = preprocess_text(df,column='description')\n",
    "    tags1 = generate_tags(df,column='description')\n",
    "    tags2 = generate_tags(df,column='job-title')\n",
    "    \n",
    "    data.append([ cat, file ,tags1,tags2 ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "4cf54ad2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T05:03:15.864484Z",
     "start_time": "2021-10-12T05:03:15.858946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### title Based ######## \n",
      "\n",
      "\n",
      " Accounting -----> Accounting_25_records.csv \n",
      "\n",
      "[('accounting', 25), ('analyst', 5), ('assistant', 4), ('specialist', 3), ('associate', 3), ('senior', 2), ('of', 2), ('finance', 2), ('director', 2), ('corporate', 2), ('vp', 1), ('undergraduate', 1), ('reporting', 1), ('remote', 1), ('portfolio', 1), ('officer', 1), ('jr', 1), ('intern', 1), ('head', 1), ('global', 1), ('financial', 1), ('executive', 1), ('customer', 1), ('coordinator', 1), ('controller', 1)] \n",
      "\n",
      "\n",
      " Mathematics -----> Mathematics_173_records.csv \n",
      "\n",
      "[('scientist', 75), ('data', 75), ('mathematics', 37), ('analyst', 18), ('associate', 14), ('applied', 14), ('research', 12), ('level', 12), ('entry', 12), ('remote', 10), ('tutor', 9), ('and', 9), ('science', 8), ('researcher', 7), ('quantitative', 7), ('intern', 7), ('in', 7), ('faculty', 6), ('math', 5), ('commercial', 5), ('teacher', 4), ('sr', 4), ('reviewer', 4), ('marketing', 4), ('assistant', 4)] \n",
      "\n",
      "\n",
      " Psychologist -----> Psychologist_75_records.csv \n",
      "\n",
      "[('psychologist', 75), ('clinical', 10), ('outpatient', 5), ('child', 4), ('licensed', 3), ('work', 2), ('time', 2), ('therapist', 2), ('staff', 2), ('research', 2), ('assistant', 2), ('young', 1), ('use', 1), ('to', 1), ('telehealth', 1), ('substance', 1), ('services', 1), ('section', 1), ('return', 1), ('remote', 1), ('psychotherapist', 1), ('practice', 1), ('positions', 1), ('part', 1), ('or', 1)] \n",
      "\n",
      "\n",
      " MechanicalEngineering -----> Mechanical_Engineering_175_records.csv \n",
      "\n",
      "[('mechanical', 154), ('engineering', 141), ('intern', 43), ('engineer', 41), ('2022', 38), ('summer', 29), ('op', 24), ('co', 24), ('internship', 17), ('spring', 12), ('design', 9), ('technician', 8), ('manufacturing', 7), ('level', 7), ('entry', 7), ('manager', 6), ('lead', 6), ('graduate', 6), ('fall', 5), ('vehicle', 4), ('specialist', 4), ('product', 4), ('junior', 4), ('technical', 3), ('project', 3)] \n",
      "\n",
      "\n",
      " Pre-Law&LegalStudies -----> Pre-Law_&_Legal_Studies_169_records.csv \n",
      "\n",
      "[('specialist', 41), ('legal', 30), ('counsel', 24), ('assistant', 23), ('litigation', 18), ('law', 18), ('contracts', 18), ('manager', 16), ('corporate', 16), ('operations', 15), ('associate', 15), ('investigator', 13), ('fraud', 13), ('claims', 13), ('pre', 11), ('senior', 10), ('paralegal', 10), ('government', 9), ('compliance', 9), ('analyst', 9), ('remote', 8), ('services', 7), ('office', 6), ('firm', 6), ('entry', 6)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('###### title Based ########','\\n')    \n",
    "for j in data:\n",
    "    print('\\n',j[0],'----->',j[1],'\\n')\n",
    "    print(j[3],'\\n')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "da00427c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T05:03:15.877843Z",
     "start_time": "2021-10-12T05:03:15.865999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### description Based ######## \n",
      "\n",
      "\n",
      " Accounting -----> Accounting_25_records.csv \n",
      "\n",
      "[('accounting', 125), ('team', 51), ('company', 51), ('finance', 44), ('experience', 42), ('process', 40), ('job', 38), ('work', 37), ('function', 36), ('ability', 36), ('employment', 35), ('type', 32), ('opportunity', 31), ('skill', 30), ('customer', 27), ('management', 26), ('service', 24), ('business', 24), ('year', 23), ('status', 22), ('project', 22), ('responsibility', 21), ('position', 21), ('level', 21), ('employee', 21)] \n",
      "\n",
      "\n",
      " Mathematics -----> Mathematics_173_records.csv \n",
      "\n",
      "[('datum', 523), ('experience', 427), ('team', 291), ('work', 274), ('job', 269), ('science', 257), ('research', 247), ('employment', 243), ('technology', 238), ('level', 237), ('business', 234), ('student', 215), ('ability', 208), ('information', 207), ('opportunity', 203), ('industry', 194), ('skill', 189), ('model', 183), ('analysis', 175), ('product', 170), ('data', 163), ('knowledge', 161), ('type', 157), ('development', 156), ('program', 153)] \n",
      "\n",
      "\n",
      " Psychologist -----> Psychologist_75_records.csv \n",
      "\n",
      "[('health', 506), ('care', 371), ('service', 239), ('psychologist', 195), ('patient', 166), ('team', 143), ('practice', 143), ('work', 141), ('treatment', 140), ('experience', 135), ('level', 121), ('job', 118), ('provider', 115), ('employment', 102), ('time', 101), ('education', 100), ('child', 99), ('opportunity', 96), ('support', 89), ('program', 87), ('research', 86), ('psychology', 83), ('community', 83), ('type', 81), ('environment', 81)] \n",
      "\n",
      "\n",
      " MechanicalEngineering -----> Mechanical_Engineering_175_records.csv \n",
      "\n",
      "[('engineering', 831), ('design', 598), ('team', 483), ('experience', 453), ('work', 420), ('product', 391), ('technology', 347), ('system', 298), ('job', 281), ('employment', 264), ('level', 259), ('project', 256), ('information', 256), ('development', 250), ('engineer', 248), ('industry', 233), ('process', 214), ('internship', 207), ('program', 199), ('opportunity', 191), ('status', 188), ('manufacturing', 187), ('type', 182), ('solution', 180), ('skill', 177)] \n",
      "\n",
      "\n",
      " Pre-Law&LegalStudies -----> Pre-Law_&_Legal_Studies_169_records.csv \n",
      "\n",
      "[('experience', 417), ('law', 367), ('work', 319), ('service', 309), ('contract', 282), ('business', 277), ('team', 276), ('job', 275), ('ability', 241), ('level', 234), ('information', 233), ('skill', 225), ('employment', 225), ('management', 217), ('company', 208), ('client', 199), ('position', 194), ('industry', 175), ('type', 164), ('year', 163), ('process', 163), ('function', 155), ('compliance', 154), ('research', 153), ('employee', 153)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('###### description Based ########','\\n')    \n",
    "for j in data:\n",
    "    print('\\n',j[0],'----->',j[1],'\\n')\n",
    "    print(j[2],'\\n')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54cf312",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T04:57:27.265866Z",
     "start_time": "2021-10-12T04:57:27.254637Z"
    }
   },
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e1016f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T04:27:31.569201Z",
     "start_time": "2021-10-12T04:27:31.555169Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2914dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T04:31:07.554889Z",
     "start_time": "2021-10-12T04:31:03.261654Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531210c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T04:31:07.560300Z",
     "start_time": "2021-10-12T04:31:07.556153Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d4d58a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T04:27:34.193854Z",
     "start_time": "2021-10-12T04:27:34.183088Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40ee638",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T04:39:08.914181Z",
     "start_time": "2021-10-12T04:39:08.882512Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ebef86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T04:36:15.930219Z",
     "start_time": "2021-10-12T04:36:15.927047Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc3f1ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b722b9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T04:18:12.557420Z",
     "start_time": "2021-10-12T04:18:08.666975Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eeb626",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95325a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb7adf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972307a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7715dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
